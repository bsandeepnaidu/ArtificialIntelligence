{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGyHWbOM70HN"
   },
   "source": [
    "## Image Classification\n",
    "\n",
    "\n",
    "Image classification is one of the important use cases in our daily life. Automotive, e-commerce, retail, manufacturing industries, security, surveillance, healthcare, farming etc., can have a wide application of image classification.\n",
    "\n",
    "**Objective:** In this notebook, we will build a neural network to classifiy the image based on the object present in the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LSdjqV35-j_"
   },
   "source": [
    "\n",
    "## Advanced techniques for training neural networks\n",
    "\n",
    "* Weight Initialization\n",
    "\n",
    "* Nonlinearity (different Activation functions)\n",
    "\n",
    "* Optimizers(different optimizers)\n",
    "\n",
    "* Batch Normalization\n",
    "\n",
    "* Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfL8u4jx82pG"
   },
   "source": [
    "### About Dataset\n",
    "\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "#### Labels\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "0 T-shirt/top\n",
    "\n",
    "1 Trouser\n",
    "\n",
    "2 Pullover\n",
    "\n",
    "3 Dress\n",
    "\n",
    "4 Coat\n",
    "\n",
    "5 Sandal\n",
    "\n",
    "6 Shirt\n",
    "\n",
    "7 Sneaker\n",
    "\n",
    "8 Bag\n",
    "\n",
    "9 Ankle boot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XGznu8t6HBc"
   },
   "source": [
    "### Load dataset\n",
    "\n",
    "Fashion-MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3m64izx05_VU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow \n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9GEM4h0IoCfW",
    "outputId": "e327094f-f40f-4fb4-b977-b8581ba9bbfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eAkQmLqP6I2W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.shape == (60000, 28, 28)\n",
    "assert X_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQGRwOCjqW2G",
    "outputId": "56998997-e594-4ebd-b320-8f8970ff0e74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HLg43FhqaTI",
    "outputId": "d2057d11-128f-403f-8e79-4e8663920148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmOeRO1OqhGu",
    "outputId": "050d149d-10e4-46c0-a2f4-67c02fb4594b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uwl3GH0BqjdX",
    "outputId": "d13df9d2-527e-4268-d369-59653e28357e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Mr5bH4OY6Ndk",
    "outputId": "7ca7b04a-a2da-4002-90fa-75268af3d753"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  9\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[0])    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "bcTZqYFj6PcB",
    "outputId": "51bdd727-20b1-4007-92d2-18a27f7ca092"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  2\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_test[1])    # show first number in the dataset\n",
    "plt.show()\n",
    "print('Label: ', y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(y_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test =X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZxmqqAa9Cz7"
   },
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5TCY3Jnm6RHr"
   },
   "outputs": [],
   "source": [
    "# reshaping X data: (n, 28, 28) => (n, 784)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oG06URdH6Vvv"
   },
   "outputs": [],
   "source": [
    "# converting y data into categorical (one-hot encoding)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71HK9T0P6Y2G",
    "outputId": "4dae4b81-858a-44a0-9c4a-d08bf93902e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784) (60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb0Kx_ME6plD"
   },
   "source": [
    "### Basic NN model\n",
    "\n",
    "Naive MLP model without any alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "weHT53gF6aFY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izZlXqJu6sdo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input -> Hidden Layer -> HL-> ---- ->OP["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3dCi-i296tuq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandeep\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape = (784, )))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PJ5FUE916x2b"
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(learning_rate = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000/1875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zl34l0jR6zH-",
    "outputId": "aa7b0616-8fab-4b57-f566-fec524c1c370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0975 - loss: 2.3704\n",
      "Epoch 2/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1003 - loss: 2.3027\n",
      "Epoch 3/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1020 - loss: 2.3025\n",
      "Epoch 4/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1074 - loss: 2.3023\n",
      "Epoch 5/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1043 - loss: 2.3021\n",
      "Epoch 6/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1110 - loss: 2.3019\n",
      "Epoch 7/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1155 - loss: 2.3016\n",
      "Epoch 8/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1221 - loss: 2.3014\n",
      "Epoch 9/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1208 - loss: 2.3012\n",
      "Epoch 10/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1222 - loss: 2.3010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size =200, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1114 - loss: 2.3010\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1185 - loss: 2.2994\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1243 - loss: 2.2963\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1472 - loss: 2.2902\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1733 - loss: 2.2763\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2599 - loss: 2.2192\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2777 - loss: 1.9280\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3542 - loss: 1.6593\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4037 - loss: 1.5135\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4644 - loss: 1.3959\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size =32, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rhl0xqgR62ei",
    "outputId": "7d8aa549-c3ac-4ae1-e638-e9ca70647c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5111 - loss: 1.3354\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PSheNKy66Iu",
    "outputId": "25620bd7-e083-4d12-b70e-21762a1d0c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5108000040054321\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3V7kN5-f7IHv"
   },
   "source": [
    "### 1. Weight Initialization\n",
    "\n",
    "Changing weight initialization scheme can significantly improve training of the model by preventing vanishing gradient problem up to some degree\n",
    "\n",
    "Ref: https://keras.io/initializers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1032 - loss: 2.3035\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3035\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1004 - loss: 2.3035\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1001 - loss: 2.3037\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1001 - loss: 2.3036\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3036\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0988 - loss: 2.3037\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3036\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0987 - loss: 2.3036\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1022 - loss: 2.3034\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0962 - loss: 2.3038\n",
      "Test accuracy:  0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape = (784, ),kernel_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50,kernel_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50,kernel_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50,kernel_initializer='zeros'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10,kernel_initializer='ones'))\n",
    "model.add(Activation('softmax'))\n",
    "sgd = optimizers.SGD(learning_rate = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size = 32, epochs = 10, verbose = 1)\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3062 - accuracy: 0.0985\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3066 - accuracy: 0.0992\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3063 - accuracy: 0.1011\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3061 - accuracy: 0.1001\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3063 - accuracy: 0.0998\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3062 - accuracy: 0.1001\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3066 - accuracy: 0.0995\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3062 - accuracy: 0.1003\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3064 - accuracy: 0.1010\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3064 - accuracy: 0.0986\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 2.3054 - accuracy: 0.1000\n",
      "Test accuracy:  0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape = (784, ),kernel_initializer='ones'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50,kernel_initializer='ones'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50,kernel_initializer='ones'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50,kernel_initializer='ones'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10,kernel_initializer='ones'))\n",
    "model.add(Activation('softmax'))\n",
    "sgd = optimizers.SGD(learning_rate = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size = 32, epochs = 10, verbose = 1)\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7il0ZpZZ67GP"
   },
   "outputs": [],
   "source": [
    "# from now on, create a function to generate (return) models\n",
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(learning_rate = 0.01)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9iOQeOzR7Q2O",
    "outputId": "b59f94cc-7902-470d-b607-9c1e40b67ccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3068 - accuracy: 0.1169\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.2859 - accuracy: 0.1651\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.2447 - accuracy: 0.2653\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0179 - accuracy: 0.3095\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.6714 - accuracy: 0.3808\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4771 - accuracy: 0.4514\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.3298 - accuracy: 0.5222\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.2090 - accuracy: 0.5684\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.1088 - accuracy: 0.5874\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.0333 - accuracy: 0.6083\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThB85Acn7SFu",
    "outputId": "eefcb90d-6890-4a61-eee6-03e583110ed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 1.0119 - accuracy: 0.6112\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iq5a7na67UgU",
    "outputId": "4d630a10-1955-4ad3-eedf-0ac6c0137206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.6111999750137329\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from now on, create a function to generate (return) models\n",
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, ), kernel_initializer='glorot_normal'))     # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='glorot_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='glorot_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='glorot_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(10, kernel_initializer='glorot_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(learning_rate = 0.01)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3048 - accuracy: 0.1004\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3028 - accuracy: 0.1034\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3017 - accuracy: 0.1066\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3005 - accuracy: 0.1149\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.2987 - accuracy: 0.1204\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.2956 - accuracy: 0.1345\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.2889 - accuracy: 0.1636\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.2700 - accuracy: 0.2156\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.1762 - accuracy: 0.2361\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.8550 - accuracy: 0.2542\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7223 - accuracy: 0.3140\n",
      "Test accuracy:  0.3140000104904175\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs = 10, verbose = 1)\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5M6EHv17YUV"
   },
   "source": [
    "### 2. Nonlinearity (Activation function)\n",
    "\n",
    "Sigmoid functions suffer from gradient vanishing problem, making training slower\n",
    "\n",
    "There are many choices apart from sigmoid and tanh; try many of them!\n",
    "\n",
    "'relu' (rectified linear unit) is one of the most popular ones\n",
    "\n",
    "Ref: https://keras.io/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "BuuRRvxL7WU1"
   },
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, ),kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50,kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50,kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50,kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(10,kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(learning_rate = 0.01)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHqen6477eRZ",
    "outputId": "a41ec3e9-ad52-4674-a117-acd3aa401757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7207 - accuracy: 0.7409\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4775 - accuracy: 0.8295\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4244 - accuracy: 0.8485\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3935 - accuracy: 0.8583\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3745 - accuracy: 0.8634\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3599 - accuracy: 0.8700\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3470 - accuracy: 0.8740\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3370 - accuracy: 0.8761\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3293 - accuracy: 0.8792\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3206 - accuracy: 0.8822\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train,batch_size=32, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLrEe_Kn7fha",
    "outputId": "087c69a6-e520-4135-c12f-133384900186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3772 - accuracy: 0.8650\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBUqrqSd7heP",
    "outputId": "64accf12-c58d-429f-bc8e-bca6ae946cac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8650000095367432\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, ),kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50,kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50,kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50,kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(10,kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 2.8026 - accuracy: 0.6898\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7289 - accuracy: 0.7718\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5818 - accuracy: 0.8049\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5313 - accuracy: 0.8174\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4927 - accuracy: 0.8278\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4627 - accuracy: 0.8376\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4378 - accuracy: 0.8459\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4187 - accuracy: 0.8523\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4114 - accuracy: 0.8520\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3959 - accuracy: 0.8583\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4555 - accuracy: 0.8384\n",
      "Test accuracy:  0.8384000062942505\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train,batch_size=32, epochs = 10, verbose = 1)\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lp_-o2ug70fF"
   },
   "source": [
    "### 3. Batch Normalization\n",
    "\n",
    "Batch Normalization, one of the methods to prevent the \"internal covariance shift\" problem, has proven to be highly effective\n",
    "\n",
    "Normalize each mini-batch before nonlinearity\n",
    "\n",
    "Ref: https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "buhn2kOY7yg8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YrSd0LT78Yi"
   },
   "source": [
    "Batch normalization layer is usually inserted after dense/convolution and before nonlinearity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "10InY0e_77M7"
   },
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, ),kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50,kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50,kernel_initializer='he_normal'))\n",
    "    #model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(50,kernel_initializer='he_normal'))\n",
    "    #model.add(BatchNormalization())                    \n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(10,kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOCywkTg79_W",
    "outputId": "4d659c7b-0145-4652-f1d9-46c8e77148a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.5166 - accuracy: 0.8155\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3888 - accuracy: 0.8579\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3577 - accuracy: 0.8695\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3387 - accuracy: 0.8753\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3198 - accuracy: 0.8823\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3105 - accuracy: 0.8836\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2986 - accuracy: 0.8895\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2860 - accuracy: 0.8944\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2824 - accuracy: 0.8960\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2729 - accuracy: 0.8982\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size=32,epochs = 10, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGodrhsc8AW7",
    "outputId": "082c15e5-d909-449e-d2eb-bb87a012a628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3685 - accuracy: 0.8671\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDnDxm8r8Bt0",
    "outputId": "3ed94494-acde-48eb-f04e-5287aa1be3da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8671000003814697\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElSuYRBH8yim"
   },
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "gKXR7REP8C8s"
   },
   "outputs": [],
   "source": [
    "def mlp_model(drop=0.2):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, ), kernel_initializer='he_normal'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FJsCqh680bq",
    "outputId": "3546c1ba-bd70-4240-bbee-7ee7808bdb59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8491 - accuracy: 0.6799 - val_loss: 0.5109 - val_accuracy: 0.8039\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5711 - accuracy: 0.7967 - val_loss: 0.4751 - val_accuracy: 0.8233\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5204 - accuracy: 0.8165 - val_loss: 0.4362 - val_accuracy: 0.8410\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4875 - accuracy: 0.8283 - val_loss: 0.4246 - val_accuracy: 0.8477\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4710 - accuracy: 0.8348 - val_loss: 0.4351 - val_accuracy: 0.8346\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4597 - accuracy: 0.8384 - val_loss: 0.4083 - val_accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4468 - accuracy: 0.8424 - val_loss: 0.4016 - val_accuracy: 0.8531\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4381 - accuracy: 0.8457 - val_loss: 0.4070 - val_accuracy: 0.8479\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4327 - accuracy: 0.8468 - val_loss: 0.3954 - val_accuracy: 0.8568\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4257 - accuracy: 0.8489 - val_loss: 0.4157 - val_accuracy: 0.8556\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, epochs = 10,batch_size=32,validation_data=(X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TY58JhC085IM",
    "outputId": "51508c12-b3f0-479f-bf40-c411cb3ac95c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4157 - accuracy: 0.8556\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SU5NUjzs85KT",
    "outputId": "a9638d68-54a4-47ac-e01a-40d061b114d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8555999994277954\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb66vQo-KsM_"
   },
   "source": [
    "#### Dropouts and BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BatchNormalization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m adam, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmlp_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test), verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     29\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)    \n",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m, in \u001b[0;36mmlp_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m50\u001b[39m, input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m784\u001b[39m, )))\n\u001b[1;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mBatchNormalization\u001b[49m())\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.2\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BatchNormalization' is not defined"
     ]
    }
   ],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, epochs = 10,batch_size=32,validation_data=(X_test, y_test), verbose = 1)\n",
    "results = model.evaluate(X_test, y_test)    \n",
    "print('Test accuracy: ', results[1])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5753 - accuracy: 0.7914 - val_loss: 0.4406 - val_accuracy: 0.8404\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4208 - accuracy: 0.8442 - val_loss: 0.3980 - val_accuracy: 0.8536\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3878 - accuracy: 0.8572 - val_loss: 0.3902 - val_accuracy: 0.8568\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3689 - accuracy: 0.8629 - val_loss: 0.4108 - val_accuracy: 0.8529\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3543 - accuracy: 0.8690 - val_loss: 0.3566 - val_accuracy: 0.8700\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3431 - accuracy: 0.8726 - val_loss: 0.3690 - val_accuracy: 0.8666\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3317 - accuracy: 0.8765 - val_loss: 0.3582 - val_accuracy: 0.8701\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3247 - accuracy: 0.8802 - val_loss: 0.3602 - val_accuracy: 0.8675\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3155 - accuracy: 0.8832 - val_loss: 0.3494 - val_accuracy: 0.8740\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3132 - accuracy: 0.8843 - val_loss: 0.3454 - val_accuracy: 0.8749\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8749\n",
      "Test accuracy:  0.8748999834060669\n"
     ]
    }
   ],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, )))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))    \n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, epochs = 10,batch_size=32,validation_data=(X_test, y_test), verbose = 1)\n",
    "results = model.evaluate(X_test, y_test)    \n",
    "print('Test accuracy: ', results[1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.5215 - accuracy: 0.8122 - val_loss: 0.4156 - val_accuracy: 0.8519\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3853 - accuracy: 0.8595 - val_loss: 0.4128 - val_accuracy: 0.8519\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3557 - accuracy: 0.8704 - val_loss: 0.3780 - val_accuracy: 0.8634\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3287 - accuracy: 0.8791 - val_loss: 0.3514 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3141 - accuracy: 0.8834 - val_loss: 0.3421 - val_accuracy: 0.8754\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2998 - accuracy: 0.8881 - val_loss: 0.3342 - val_accuracy: 0.8838\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2874 - accuracy: 0.8937 - val_loss: 0.3333 - val_accuracy: 0.8850\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2782 - accuracy: 0.8963 - val_loss: 0.3304 - val_accuracy: 0.8852\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2703 - accuracy: 0.8975 - val_loss: 0.3362 - val_accuracy: 0.8785\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2612 - accuracy: 0.9022 - val_loss: 0.3351 - val_accuracy: 0.8800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8800\n",
      "Test accuracy:  0.8799999952316284\n"
     ]
    }
   ],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(256, input_shape = (784, )))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))    \n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, epochs = 10,batch_size=32,validation_data=(X_test, y_test), verbose = 1)\n",
    "results = model.evaluate(X_test, y_test)    \n",
    "print('Test accuracy: ', results[1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# fname = os.path.sep.join([args[\"weights\"],\"weights-{epoch:03d}-{val_loss:.4f}.hdf5\"])\n",
    "checkpoint = ModelCheckpoint(\"Best.weights.h5\", monitor=\"val_loss\", mode=\"min\",save_best_only=True, verbose=1,save_weights_only=True)\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1871/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - loss: 0.6946\n",
      "Epoch 1: val_loss improved from inf to 0.41781, saving model to Best.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6942 - val_accuracy: 0.8484 - val_loss: 0.4178\n",
      "Epoch 2/10\n",
      "\u001b[1m1866/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.4067\n",
      "Epoch 2: val_loss improved from 0.41781 to 0.41140, saving model to Best.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.4066 - val_accuracy: 0.8493 - val_loss: 0.4114\n",
      "Epoch 3/10\n",
      "\u001b[1m1871/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.3696\n",
      "Epoch 3: val_loss improved from 0.41140 to 0.38635, saving model to Best.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.3696 - val_accuracy: 0.8563 - val_loss: 0.3864\n",
      "Epoch 4/10\n",
      "\u001b[1m1864/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3475\n",
      "Epoch 4: val_loss did not improve from 0.38635\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3475 - val_accuracy: 0.8501 - val_loss: 0.3979\n",
      "Epoch 5/10\n",
      "\u001b[1m1869/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.3243\n",
      "Epoch 5: val_loss improved from 0.38635 to 0.38159, saving model to Best.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.3243 - val_accuracy: 0.8645 - val_loss: 0.3816\n",
      "Epoch 6/10\n",
      "\u001b[1m1864/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.3062\n",
      "Epoch 6: val_loss did not improve from 0.38159\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.3062 - val_accuracy: 0.8501 - val_loss: 0.3865\n",
      "Epoch 7/10\n",
      "\u001b[1m1869/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.2970\n",
      "Epoch 7: val_loss improved from 0.38159 to 0.32476, saving model to Best.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.2970 - val_accuracy: 0.8832 - val_loss: 0.3248\n",
      "Epoch 8/10\n",
      "\u001b[1m1863/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.2888\n",
      "Epoch 8: val_loss did not improve from 0.32476\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.2888 - val_accuracy: 0.8664 - val_loss: 0.3674\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2748\n",
      "Epoch 9: val_loss did not improve from 0.32476\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2748 - val_accuracy: 0.8846 - val_loss: 0.3263\n",
      "Epoch 10/10\n",
      "\u001b[1m1872/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.2675\n",
      "Epoch 10: val_loss improved from 0.32476 to 0.31417, saving model to Best.weights.h5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.2675 - val_accuracy: 0.8845 - val_loss: 0.3142\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8829 - loss: 0.3200\n",
      "Test accuracy:  0.8845000267028809\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(256, input_shape = (784, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train,batch_size=32,validation_data=(X_test, y_test), epochs = 10, verbose = 1,callbacks=callbacks)\n",
    "results = model.evaluate(X_test, y_test)    \n",
    "print('Test accuracy: ', results[1])\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image_Classification_Intro_to_NN_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
